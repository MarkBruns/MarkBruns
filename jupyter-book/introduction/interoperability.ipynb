{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have discussed in the {ref}`analysis frameworks and tools chapter <introduction:analysis-frameworks>` there are three main ecosystems for single-cell analysis, the [Bioconductor](https://bioconductor.org/) and [Seurat](https://satijalab.org/seurat/index.html) ecosystems in R and the Python-based [scverse](https://scverse.org/) ecosystem. A common question from new analysts is which ecosystem they should focus on learning and using? While it makes sense to focus on one to start with, and a successful standard analysis can be performed in any ecosystem, we promote the idea that competent analysts should be familiar with all three ecosystems and comfortable moving between them. This approach allows analysts to use the best-performing tools and methods regardless of how they were implemented. When analysts are not comfortable moving between ecosystems they often tend to use packages that are easy to access, even when they have been shown to have shortcomings compared to packages in another ecosystem. The ability of analysts to move between ecosystems allows developers to take advantage of the different strengths of programming languages. For example, R has strong inbuilt support for complex statistical modelling while the majority of deep learning libraries are focused on Python. By supporting common on-disk data formats and in-memory data structures developers can be confident that analysts can access their package and focus on using the most appropriate platform for their method. Another motivation for being comfortable with multiple is the accessibility and availability of data, results and documentation. Often data or results are only made available in one format and analysts will need to be familiar with that format in order to access it. A basic understanding of other ecosystems is also necessary to understand package documentation and tutorials when deciding which methods to use.\n",
    "\n",
    "While we encourage analysts to be comfortable with all the major ecosystems, moving between them is only possible when they are interoperable. Thankfully lots of work has been done in this area and it is now relatively simple in most cases using standard packages. In this chapter, we discuss the various ways data can be moved between ecosystems via disk or in-memory, the differences between them and their advantages. We focus on single-modality data and moving between R and Python as these are the most common cases but we also touch on multimodal data and other languages.\n",
    "\n",
    "Because talking about different languages can get confusing we try to use the following conventions:\n",
    "\n",
    "- **{package}** - An R package\n",
    "- `package::function()` - A function in an R package\n",
    "- **package** - A Python package\n",
    "- `package.function()` - A function in a Python package\n",
    "- **Emphasised** - Some other important concept\n",
    "- `code` - Other parts of code including objects, variables etc. This is also used for files or directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata\n",
    "import numpy\n",
    "import scanpy\n",
    "import tempfile\n",
    "import os\n",
    "import rpy2.robjects\n",
    "import anndata2ri\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "anndata2ri.activate()\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disk-based interoperability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach to moving between languages is via disk-based interoperability. This involves writing a file to disk in one language and then reading that file into a second language. In many cases, this approach is simpler, more reliable and scalable than in-memory interoperability (which we discuss below) but it comes at the cost of greater storage requirements and reduced interactivity. Disk-based interoperability tends to work particularly well when there are established processes for each stage of analysis and you want to pass objects from one to the next (especially as part of a pipeline developed using a workflow manager such as [NextFlow](https://www.nextflow.io/index.html) or [snakemake](https://snakemake.readthedocs.io/en/stable/)). However, disk-based interoperability is less convenient for interactive steps such as data exploration or experimenting with methods as you need to write a new file whenever you want to move between languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before discussing file formats specifically developed for single-cell data we want to briefly mention that common simple text file formats (such as CSV, TSV, JSON etc.) can often be the answer to transferring data between languages. They work well in cases where some analysis has been performed and what you want to transfer is a subset of the information about an experiment. For example, you may want to transfer only the cell metadata but do not require the feature metadata, expression matrices etc. The advantage of using simple text formats is that they are well supported by almost any language and do not require single-cell specific packages. However, they can quickly become impractical as what you want to transfer becomes more complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5-based formats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common disk formats for single-cell data are based on [Hierarchical Data Format version 5](https://www.hdfgroup.org/solutions/hdf5/) or HDF5. This is an open-source file format designed for storing large, complex and heterogeneous data. It has a file directory type structure (similar to how files and folders are organised on your computer) which allows many different kinds of data to be stored in a single file with an arbitrarily complex hierarchy. While this format is very flexible, to properly interact with it you need to know where and how the different information is stored. For this reason, standard specifications for storing single-cell data in HDF5 files have been developed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H5AD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The H5AD format is the HDF5 disk representation of the `AnnData` object used by scverse packages and is commonly used to share single-cell datasets. As it is part of the scverse ecosystem, reading and writing these files from Python is well-supported and is part of the core functionality of the [**anndata** package](https://anndata.readthedocs.io/en/latest/index.html) (read more about the format [here](https://anndata.readthedocs.io/en/latest/fileformat-prose.html)).\n",
    "\n",
    "To demonstrate interoperability we will use a small randomly generated dataset that has gone through some of the steps of a standard analysis workflow to populate the various slots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke.zappia/miniconda3/envs/interoperability/lib/python3.9/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/luke.zappia/miniconda3/envs/interoperability/lib/python3.9/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/luke.zappia/miniconda3/envs/interoperability/lib/python3.9/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n",
      "/Users/luke.zappia/miniconda3/envs/interoperability/lib/python3.9/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 100 × 2000\n",
       "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
       "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'log1p', 'hvg', 'pca', 'neighbors', 'umap'\n",
       "    obsm: 'X_pca', 'X_umap'\n",
       "    varm: 'PCs'\n",
       "    layers: 'counts'\n",
       "    obsp: 'distances', 'connectivities'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a randomly generated AnnData object to use as an example\n",
    "counts = csr_matrix(numpy.random.poisson(1, size=(100, 2000)), dtype=numpy.float32)\n",
    "adata = anndata.AnnData(counts)\n",
    "adata.obs_names = [f\"Cell_{i:d}\" for i in range(adata.n_obs)]\n",
    "adata.var_names = [f\"Gene_{i:d}\" for i in range(adata.n_vars)]\n",
    "# Do some standard processing to populate the object\n",
    "scanpy.pp.calculate_qc_metrics(adata, inplace=True)\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "scanpy.pp.normalize_total(adata, inplace=True)\n",
    "scanpy.pp.log1p(adata)\n",
    "scanpy.pp.highly_variable_genes(adata, inplace=True)\n",
    "scanpy.tl.pca(adata)\n",
    "scanpy.pp.neighbors(adata)\n",
    "scanpy.tl.umap(adata)\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will write this mock object to disk as a H5AD file to demonstrate how those files can be read from R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "h5ad_file = os.path.join(temp_dir.name, \"example.h5ad\")\n",
    "\n",
    "adata.write_h5ad(h5ad_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several packages exist for reading and writing H5AD files from R. While they result in a file on disk these packages usually rely on wrapping the Python **anndata** package to handle the actual reading and writing of files with an in-memory conversion step to convert between R and Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading/writing H5AD with Bioconductor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Bioconductor **{zellkonverter}** package](https://bioconductor.org/packages/zellkonverter/) helps makes this easier by using the [**{basilisk}** package](https://bioconductor.org/packages/basilisk/) to manage creating an appropriate Python environment. If that all sounds a bit technical, the end result is that Bioconductor users can read and write H5AD files using commands like below without requiring any knowledge of Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, because of the way this book is made we are unable to run the code directly here. Instead we will show the code and what the output looks like when run in an R session:\n",
    "\n",
    "```r\n",
    "sce <- zellkonverter::readH5AD(h5ad_file, verbose = TRUE)\n",
    "```\n",
    "\n",
    "```\n",
    "ℹ Using the Python reader\n",
    "ℹ Using anndata version 0.8.0\n",
    "✔ Read /.../luke.zappia/Downloads/example.h5ad [113ms]\n",
    "✔ uns$hvg$flavor converted [17ms]\n",
    "✔ uns$hvg converted [50ms]\n",
    "✔ uns$log1p converted [25ms]\n",
    "✔ uns$neighbors converted [18ms]\n",
    "✔ uns$pca$params$use_highly_variable converted [16ms]\n",
    "✔ uns$pca$params$zero_center converted [16ms]\n",
    "✔ uns$pca$params converted [80ms]\n",
    "✔ uns$pca$variance converted [17ms]\n",
    "✔ uns$pca$variance_ratio converted [16ms]\n",
    "✔ uns$pca converted [184ms]\n",
    "✔ uns$umap$params$a converted [16ms]\n",
    "✔ uns$umap$params$b converted [16ms]\n",
    "✔ uns$umap$params converted [80ms]\n",
    "✔ uns$umap converted [112ms]\n",
    "✔ uns converted [490ms]\n",
    "✔ Converting uns to metadata ... done\n",
    "✔ X matrix converted to assay [29ms]\n",
    "✔ layers$counts converted [27ms]\n",
    "✔ Converting layers to assays ... done\n",
    "✔ var converted to rowData [25ms]\n",
    "✔ obs converted to colData [24ms]\n",
    "✔ varm$PCs converted [18ms]\n",
    "✔ varm converted [47ms]\n",
    "✔ Converting varm to rowData$varm ... done\n",
    "✔ obsm$X_pca converted [15ms]\n",
    "✔ obsm$X_umap converted [16ms]\n",
    "✔ obsm converted [80ms]\n",
    "✔ Converting obsm to reducedDims ... done\n",
    "ℹ varp is empty and was skipped\n",
    "✔ obsp$connectivities converted [22ms]\n",
    "✔ obsp$distances converted [23ms]\n",
    "✔ obsp converted [92ms]\n",
    "✔ Converting obsp to colPairs ... done\n",
    "✔ SingleCellExperiment constructed [164ms]\n",
    "ℹ Skipping conversion of raw\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "```\n",
    "\n",
    "Because we have turned on the verbose output you can see how **{zellkonverter}** reads the file using Python and converts each part of the `AnnData` object to a Bioconductor `SingleCellExperiment` object. We can see what the result looks like:\n",
    "\n",
    "```r\n",
    "sce\n",
    "```\n",
    "\n",
    "```\n",
    "class: SingleCellExperiment\n",
    "dim: 2000 100\n",
    "metadata(5): hvg log1p neighbors pca umap\n",
    "assays(2): X counts\n",
    "rownames(2000): Gene_0 Gene_1 ... Gene_1998 Gene_1999\n",
    "rowData names(11): n_cells_by_counts mean_counts ... dispersions_norm\n",
    "  varm\n",
    "colnames(100): Cell_0 Cell_1 ... Cell_98 Cell_99\n",
    "colData names(8): n_genes_by_counts log1p_n_genes_by_counts ...\n",
    "  pct_counts_in_top_200_genes pct_counts_in_top_500_genes\n",
    "reducedDimNames(2): X_pca X_umap\n",
    "mainExpName: NULL\n",
    "altExpNames(0):\n",
    "```\n",
    "\n",
    "This object can then be used as normal by any Bioconductor package. If we want to write a new H5AD file we can use the `writeH5AD()` function:\n",
    "\n",
    "```r\n",
    "zellkonverter_h5ad_file <- tempfile(fileext = \".h5ad\")\n",
    "zellkonverter::writeH5AD(sce, zellkonverter_h5ad_file, verbose = TRUE)\n",
    "```\n",
    "\n",
    "```\n",
    "ℹ Using anndata version 0.8.0\n",
    "ℹ Using the 'X' assay as the X matrix\n",
    "✔ Selected X matrix [29ms]\n",
    "✔ assays$X converted to X matrix [50ms]\n",
    "✔ additional assays converted to layers [30ms]\n",
    "✔ rowData$varm converted to varm [28ms]\n",
    "✔ reducedDims converted to obsm [68ms]\n",
    "✔ metadata converted to uns [24ms]\n",
    "ℹ rowPairs is empty and was skipped\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "✔ Wrote '/.../.../rj/.../T/.../file102cfa97cc51.h5ad ' [133ms]\n",
    "```\n",
    "\n",
    "We can then read this file in Python:\n",
    "\n",
    "```python\n",
    "scanpy.read_h5ad(zellkonverter_h5ad_file)\n",
    "```\n",
    "\n",
    "```\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'X_name', 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this the first time that you run a **{zellkonverter}** you will see that it first creates a special conda environment to use (which can take a while). Once that environment exists it will be re-used by following function calls. **{zellkonverter}** has additional options such as allowing you to selectively read or write parts for an object, please refer to the documentation for more details. Similar functionality for writing a `SingleCellExperimentObject` to an H5AD file can be found in the [**{sceasy}** package](https://github.com/cellgeni/sceasy). While these packages are effective, wrapping Python requires some overhead which we hope will be addressed by native R H5AD writers/readers in the future."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading/writing H5AD with **{Seurat}**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting between a `Seurat` object and an H5AD file is a two-step process [as suggested by this tutorial](https://mojaveazure.github.io/seurat-disk/articles/convert-anndata.html). Firstly H5AD file is converted to a H5Seurat file (a custom HDF5 format for `Seurat` objects) using the [**{SeuratDisk}** package](https://mojaveazure.github.io/seurat-disk/) and then this file is read as a `Seurat` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Converting H5AD to H5Seurat...\n",
      "\n",
      "R[write to console]: The legacy packages maptools, rgdal, and rgeos, underpinning the sp package,\n",
      "which was just loaded, will retire in October 2023.\n",
      "Please refer to R-spatial evolution reports for details, especially\n",
      "https://r-spatial.org/r/2023/05/15/evolution4.html.\n",
      "It may be desirable to make the sf package available;\n",
      "package maintainers should consider adding sf to Suggests:.\n",
      "The sp package is now running under evolution status 2\n",
      "     (status 2 uses the sf package in place of rgdal)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    WARNING: The R package \"reticulate\" only fixed recently\n",
      "    an issue that caused a segfault when used with rpy2:\n",
      "    https://github.com/rstudio/reticulate/pull/1188\n",
      "    Make sure that you use a version of that package that includes\n",
      "    the fix.\n",
      "    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Registered S3 method overwritten by 'SeuratDisk':\n",
      "  method            from  \n",
      "  as.sparse.H5Group Seurat\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  Unknown file type: h5ad\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  'assay' not set, setting to 'RNA'\n",
      "\n",
      "R[write to console]: Creating h5Seurat file for version 3.1.5.9900\n",
      "\n",
      "R[write to console]: Adding X as data\n",
      "\n",
      "R[write to console]: Adding X as counts\n",
      "\n",
      "R[write to console]: Adding meta.features from var\n",
      "\n",
      "R[write to console]: Adding X_pca as cell embeddings for pca\n",
      "\n",
      "R[write to console]: Adding X_umap as cell embeddings for umap\n",
      "\n",
      "R[write to console]: Adding PCs as feature loadings fpr pca\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for pca\n",
      "\n",
      "R[write to console]: Adding standard deviations for pca\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for umap\n",
      "\n",
      "R[write to console]: Adding hvg to miscellaneous data\n",
      "\n",
      "R[write to console]: Adding log1p to miscellaneous data\n",
      "\n",
      "R[write to console]: Adding layer counts as data in assay counts\n",
      "\n",
      "R[write to console]: Adding layer counts as counts in assay counts\n",
      "\n",
      "R[write to console]: Reading H5Seurat...\n",
      "\n",
      "R[write to console]: Validating h5Seurat file\n",
      "\n",
      "R[write to console]: Warnung:\n",
      "R[write to console]:  Feature names cannot have underscores ('_'), replacing with dashes ('-')\n",
      "\n",
      "R[write to console]: Initializing RNA with data\n",
      "\n",
      "R[write to console]: Adding counts for RNA\n",
      "\n",
      "R[write to console]: Adding feature-level metadata for RNA\n",
      "\n",
      "R[write to console]: Adding reduction pca\n",
      "\n",
      "R[write to console]: Adding cell embeddings for pca\n",
      "\n",
      "R[write to console]: Adding feature loadings for pca\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for pca\n",
      "\n",
      "R[write to console]: Adding reduction umap\n",
      "\n",
      "R[write to console]: Adding cell embeddings for umap\n",
      "\n",
      "R[write to console]: Adding miscellaneous information for umap\n",
      "\n",
      "R[write to console]: Adding command information\n",
      "\n",
      "R[write to console]: Adding cell-level metadata\n",
      "\n",
      "R[write to console]: Read Seurat object:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An object of class Seurat \n",
      "2000 features across 100 samples within 1 assay \n",
      "Active assay: RNA (2000 features, 0 variable features)\n",
      " 2 dimensional reductions calculated: pca, umap\n"
     ]
    }
   ],
   "source": [
    "%%R -i h5ad_file\n",
    "\n",
    "message(\"Converting H5AD to H5Seurat...\")\n",
    "SeuratDisk::Convert(h5ad_file, dest = \"h5seurat\", overwrite = TRUE)\n",
    "message(\"Reading H5Seurat...\")\n",
    "h5seurat_file <- gsub(\".h5ad\", \".h5seurat\", h5ad_file)\n",
    "seurat <- SeuratDisk::LoadH5Seurat(h5seurat_file, assays = \"RNA\")\n",
    "message(\"Read Seurat object:\")\n",
    "seurat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because the structure of a `Seurat` object is quite different from `AnnData` and `SingleCellExperiment` objects the conversion process is more complex. See the [documentation of the conversion function] for more details on how this is done.\n",
    "\n",
    "The **{sceasy}** package also provides a function for reading H5AD files as `Seurat` or `SingleCellExperiment` objects in a single step. **{sceasy}** also does this by wrapping Python but unlike **{zellkonverter}** it doesn't use a special Python environment. This means you need to be responsible for setting up the environment, making sure that R can find it and that the correct packages are installed (again, this code is not run here)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "sceasy_seurat <- sceasy::convertFormat(h5ad_file, from=\"anndata\", to=\"seurat\")\n",
    "sceasy_seurat\n",
    "```\n",
    "```\n",
    "Warning: Feature names cannot have underscores ('_'), replacing with dashes ('-')\n",
    "X -> counts\n",
    "An object of class Seurat\n",
    "2000 features across 100 samples within 1 assay\n",
    "Active assay: RNA (2000 features, 0 variable features)\n",
    " 2 dimensional reductions calculated: pca, umap\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading/writing H5AD with **{anndata}**\n",
    "\n",
    "The R [**{anndata}** package](https://anndata.dynverse.org/index.html) can also be used to read H5AD files. However, unlike the packages above it does not convert to a native R object. Instead it provides an R interface to the Python object. This is useful for accessing the data but few analysis packages will accept this as input so further in-memory conversion is usually required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loom"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Loom file format](http://loompy.org/) is an older HDF5 specification for omics data. Unlike H5AD it is not linked to a specific analysis ecosystem, although the structure is similar to `AnnData` and `SingleCellExperiment` objects. Packages implementing the Loom format exist for both [R](https://github.com/mojaveazure/loomR) and [Python](https://pypi.org/project/loompy/) as well as a [Bioconductor package](https://bioconductor.org/packages/LoomExperiment/) for writing Loom files. However, it is often more convenient to use the higher-level interfaces provided by the core ecosystem packages. Apart from sharing datasets another common place Loom files are encountered is when spliced/unspliced reads are quantified using [velocycto](http://velocyto.org/) for {ref}`RNA velocity analysis <trajectories:rna-velocity>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDS files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another file format you may see used to share single-cell datasets is the RDS format. This is a binary format used to serialise arbitrary R objects (similar to Python Pickle files). As `SingleCellExperiment` and `Seurat` objects did not always have matching on-disk representations RDS files are sometimes used to share the results from R analyses. While this is ok within an analysis project we discourage its use for sharing data publicly or with collaborators due to the lack of interoperability with other ecosystems. Instead, we recommend using one of the HDF5 formats mentioned above that can be read from multiple languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New on-disk formats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While HDF5-based formats are currently the standard for on-disk representations of single-cell data other newer technologies such as [Zarr](https://zarr.dev/) and [TileDB](https://tiledb.com/) have some advantages, particularly for very large datasets and other modalities. We expect specifications to be developed for these formats in the future which may be adopted by the community (**anndata** already provides support for Zarr files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-memory interoperability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach to interoperability is to work on in-memory representations of an object. This approach involves active sessions from two programming languages running at the same time and either accessing the same object from both or converting between them as needed. Usually, one language acts as the main environment and there is an interface to the other language. This can be very useful for interactive analysis as it allows an analyst to work in two languages simultaneously. It is also often used when creating documents that use multiple languages (such as this book). However, in-memory interoperability has some drawbacks as it requires the analyst to be familiar with setting up and using both environments, more complex objects are often not supported by both languages and there is a greater memory overhead as data can easily become duplicated (making it difficult to use for larger datasets)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interoperability between R ecosystems"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at in-memory interoperability between R and Python first let’s consider the simpler case of converting between the two R ecosystems. The **{Seurat}** package provides functions for performing this conversion [as described in this vignette](https://satijalab.org/seurat/articles/conversion_vignette.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class: SingleCellExperiment \n",
      "dim: 2000 100 \n",
      "metadata(0):\n",
      "assays(2): X logcounts\n",
      "rownames(2000): Gene-0 Gene-1 ... Gene-1998 Gene-1999\n",
      "rowData names(0):\n",
      "colnames(100): Cell_0 Cell_1 ... Cell_98 Cell_99\n",
      "colData names(9): n_genes_by_counts log1p_n_genes_by_counts ...\n",
      "  pct_counts_in_top_500_genes ident\n",
      "reducedDimNames(2): PCA UMAP\n",
      "mainExpName: NULL\n",
      "altExpNames(0):\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "sce_from_seurat <- Seurat::as.SingleCellExperiment(seurat)\n",
    "sce_from_seurat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An object of class Seurat \n",
      "2000 features across 100 samples within 1 assay \n",
      "Active assay: RNA (2000 features, 0 variable features)\n",
      " 2 dimensional reductions calculated: PCA, UMAP\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "seurat_from_sce <- Seurat::as.Seurat(sce_from_seurat)\n",
    "seurat_from_sce"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difficult part here is due to the differences between the structures of the two objects. It is important to make sure the arguments are set correctly so that the conversion functions know which information to convert and where to place it.\n",
    "\n",
    "In many cases it may not be necessary to convert a `Seurat` object to a `SingleCellExperiment`. This is because many of the core Bioconductor packages for single-cell analysis have been designed to also accept a matrix as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 x 10 sparse Matrix of class \"dgCMatrix\"\n",
      "                                                                         \n",
      " [1,]    .      625.3202    .      593.0955  601.1306  628.6514 1230.1163\n",
      " [2,] 1196.7954 985.8732    .      593.0955    .       628.6514  976.7754\n",
      " [3,]    .        .         .      593.0955    .         .       618.4087\n",
      " [4,]  597.5137 625.3202  608.1254   .       601.1306    .       618.4087\n",
      " [5,]    .      625.3202  963.3317   .         .         .       618.4087\n",
      " [6,]    .      625.3202  608.1254 593.0955  601.1306    .       976.7754\n",
      " [7,]  597.5137   .      1215.2093   .         .      1247.1100  618.4087\n",
      " [8,]    .      625.3202    .      593.0955    .         .       618.4087\n",
      " [9,]  597.5137 985.8732  963.3317   .         .         .       976.7754\n",
      "[10,]    .      985.8732    .      593.0955 1202.7475  991.2440    .     \n",
      "                                 \n",
      " [1,] 614.4039 1405.3720 612.9151\n",
      " [2,] 614.4039    .        .     \n",
      " [3,] 614.4039  959.8685 612.9151\n",
      " [4,] 971.4187  605.9740 612.9151\n",
      " [5,]   .       605.9740   .     \n",
      " [6,] 614.4039  605.9740   .     \n",
      " [7,] 614.4039    .        .     \n",
      " [8,] 971.4187  605.9740   .     \n",
      " [9,]   .         .      612.9151\n",
      "[10,]   .         .      612.9151\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# Calculate Counts Per Million using the Bioconductor scuttle package\n",
    "# with a matrix in a Seurat object\n",
    "cpm <- scuttle::calculateCPM(Seurat::GetAssayData(seurat, slot = \"counts\"))\n",
    "cpm[1:10, 1:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is important to be sure you are accessing the right information and storing any results in the correct place if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing R from Python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python interface to R is provided by the [**rpy2** package](https://rpy2.github.io/doc/latest/html/index.html). This allows you to access R functions and objects from Python. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x100 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 126516 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_mat = adata.layers[\"counts\"].T\n",
    "rpy2.robjects.globalenv[\"counts_mat\"] = counts_mat\n",
    "cpm = rpy2.robjects.r(\"scuttle::calculateCPM(counts_mat)\")\n",
    "cpm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using a Jupyter notebook (as we are for this book) you can use the IPython magic interface to create cells with native R code (passing objects as required). For example, starting a cell with `%%R -i input -o output` says to take `input` as input, run R code and then return `output` as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i counts_mat -o magic_cpm\n",
    "# R code running using IPython magic\n",
    "magic_cpm <- scuttle::calculateCPM(counts_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x100 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 126516 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python code accessing the results\n",
    "magic_cpm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the approach you will most commonly see in later chapters. For more information about using **rpy2** please refer to [the documentation](https://rpy2.github.io/doc/latest/html/index.html).\n",
    "\n",
    "To work with single-cell data in this way the [**anndata2ri** package](https://icb-anndata2ri.readthedocs-hosted.com/en/latest/) is especially useful. This is an extension to **rpy2** which allows R to see `AnnData` objects as `SingleCellExperiment` objects. This avoids unnecessary conversion and makes it easy to run R code on a Python object. It also enables the conversion of sparse **scipy** matrices like we saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luke.zappia/miniconda3/envs/interoperability/lib/python3.9/functools.py:888: NotConvertedWarning: Conversion 'py2rpy' not defined for objects of type '<class 'NoneType'>'\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        sum detected total\n",
      "Cell_0 2021     1279  2021\n",
      "Cell_1 1914     1242  1914\n",
      "Cell_2 1995     1248  1995\n",
      "Cell_3 2044     1285  2044\n",
      "Cell_4 2009     1277  2009\n",
      "Cell_5 1916     1237  1916\n"
     ]
    }
   ],
   "source": [
    "%%R -i adata\n",
    "qc <- scuttle::perCellQCMetrics(adata)\n",
    "head(qc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you will still run into issues if an object (or part of it) cannot be interfaced correctly (for example if there is an unsupported data type). In that case, you may need to modify your object first before it can be accessed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Python from R"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing Python from an R session is similar to accessing R from Python but here the interface is provided by the [**{reticulate}** package](https://rstudio.github.io/reticulate/). Once it is loaded we can access Python functions and objects from R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List (26 items)\n",
      "<zip object at 0x195f45e00>\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "reticulate_list <- reticulate::r_to_py(LETTERS)\n",
    "print(reticulate_list)\n",
    "py_builtins <- reticulate::import_builtins()\n",
    "py_builtins$zip(letters, LETTERS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working in an [RMarkdown](https://rmarkdown.rstudio.com/) or [Quarto](https://quarto.org/) document you can also write native Python chunks using the **{reticulate}** Python engine. When we do this we can use the magic `r` and `py` variables to access objects in the other language (the following code is an example that is not run)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````\n",
    "```{r}\n",
    "# An R chunk that accesses a Python object\n",
    "print(py$py_object)\n",
    "```\n",
    "\n",
    "```{python}\n",
    "# A Python chunk that accesses an R object\n",
    "print(r$r_object)\n",
    "```\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike **anndata2ri**, there are no R packages that provide a direct interface for Python to view `SingleCellExperiment` or `Seurat` objects as `AnnData` objects.  However, we can still access most parts of an `AnnData` using **{reticulate}** (this code is not run)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "# Print an AnnData object in a Python environment\n",
    "py$adata\n",
    "```\n",
    "```\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```\n",
    "```r\n",
    "# Alternatively use the Python anndata package to read a H5AD file\n",
    "anndata <- reticulate::import(\"anndata\")\n",
    "anndata$read_h5ad(h5ad_file)\n",
    "```\n",
    "```\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```\n",
    "```r\n",
    "# Access the obs slot, pandas DataFrames are automatically converted to R data.frames\n",
    "head(adata$obs)\n",
    "```\n",
    "```\n",
    "       n_genes_by_counts log1p_n_genes_by_counts total_counts\n",
    "Cell_0              1246                7.128496         1965\n",
    "Cell_1              1262                7.141245         2006\n",
    "Cell_2              1262                7.141245         1958\n",
    "Cell_3              1240                7.123673         1960\n",
    "Cell_4              1296                7.167809         2027\n",
    "Cell_5              1231                7.116394         1898\n",
    "       log1p_total_counts pct_counts_in_top_50_genes\n",
    "Cell_0           7.583756                  10.025445\n",
    "Cell_1           7.604396                   9.521436\n",
    "Cell_2           7.580189                   9.959142\n",
    "Cell_3           7.581210                   9.183673\n",
    "Cell_4           7.614805                   9.718796\n",
    "Cell_5           7.549083                  10.168599\n",
    "       pct_counts_in_top_100_genes pct_counts_in_top_200_genes\n",
    "Cell_0                    17.65903                    30.89059\n",
    "Cell_1                    16.99900                    29.71087\n",
    "Cell_2                    17.62002                    30.28601\n",
    "Cell_3                    16.83673                    30.45918\n",
    "Cell_4                    17.11889                    30.04440\n",
    "Cell_5                    18.07165                    30.29505\n",
    "       pct_counts_in_top_500_genes\n",
    "Cell_0                    61.42494\n",
    "Cell_1                    59.62114\n",
    "Cell_2                    60.92952\n",
    "Cell_3                    61.07143\n",
    "Cell_4                    59.64480\n",
    "Cell_5                    61.48577\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above the R **{anndata}** package provides an R interface for `AnnData` objects but it is not currently used by many analysis packages.\n",
    "\n",
    "For more complex analysis that requires a whole object to work on it may be necessary to completely convert an object from R to Python (or the opposite). This is not memory efficient as it creates a duplicate of the data but it does provide access to a greater range of packages. The **{zellkonverter}** package provides a function for doing this conversion (note that, unlike the function for reading H5AD files, this uses the normal Python environment rather than a specially created one) (code not run). \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```r\n",
    "# Convert an AnnData to a SingleCellExperiment\n",
    "sce <- zellkonverter::AnnData2SCE(adata, verbose = TRUE)\n",
    "sce\n",
    "```\n",
    "```\n",
    "✔ uns$hvg$flavor converted [21ms]\n",
    "✔ uns$hvg converted [62ms]\n",
    "✔ uns$log1p converted [22ms]\n",
    "✔ uns$neighbors converted [21ms]\n",
    "✔ uns$pca$params$use_highly_variable converted [22ms]\n",
    "✔ uns$pca$params$zero_center converted [31ms]\n",
    "✔ uns$pca$params converted [118ms]\n",
    "✔ uns$pca$variance converted [17ms]\n",
    "✔ uns$pca$variance_ratio converted [17ms]\n",
    "✔ uns$pca converted [224ms]\n",
    "✔ uns$umap$params$a converted [15ms]\n",
    "✔ uns$umap$params$b converted [17ms]\n",
    "✔ uns$umap$params converted [80ms]\n",
    "✔ uns$umap converted [115ms]\n",
    "✔ uns converted [582ms]\n",
    "✔ Converting uns to metadata ... done\n",
    "✔ X matrix converted to assay [44ms]\n",
    "✔ layers$counts converted [29ms]\n",
    "✔ Converting layers to assays ... done\n",
    "✔ var converted to rowData [37ms]\n",
    "✔ obs converted to colData [23ms]\n",
    "✔ varm$PCs converted [18ms]\n",
    "✔ varm converted [49ms]\n",
    "✔ Converting varm to rowData$varm ... done\n",
    "✔ obsm$X_pca converted [17ms]\n",
    "✔ obsm$X_umap converted [17ms]\n",
    "✔ obsm converted [80ms]\n",
    "✔ Converting obsm to reducedDims ... done\n",
    "ℹ varp is empty and was skipped\n",
    "✔ obsp$connectivities converted [21ms]\n",
    "✔ obsp$distances converted [22ms]\n",
    "✔ obsp converted [89ms]\n",
    "✔ Converting obsp to colPairs ... done\n",
    "✔ SingleCellExperiment constructed [241ms]\n",
    "ℹ Skipping conversion of raw\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "class: SingleCellExperiment\n",
    "dim: 2000 100\n",
    "metadata(5): hvg log1p neighbors pca umap\n",
    "assays(2): X counts\n",
    "rownames(2000): Gene_0 Gene_1 ... Gene_1998 Gene_1999\n",
    "rowData names(11): n_cells_by_counts mean_counts ... dispersions_norm\n",
    "  varm\n",
    "colnames(100): Cell_0 Cell_1 ... Cell_98 Cell_99\n",
    "colData names(8): n_genes_by_counts log1p_n_genes_by_counts ...\n",
    "  pct_counts_in_top_200_genes pct_counts_in_top_500_genes\n",
    "reducedDimNames(2): X_pca X_umap\n",
    "mainExpName: NULL\n",
    "altExpNames(0):\n",
    "```\n",
    "\n",
    "The same can also be done in reverse:\n",
    "\n",
    "```r\n",
    "adata2 <- zellkonverter::SCE2AnnData(sce, verbose = TRUE)\n",
    "adata2\n",
    "```\n",
    "```\n",
    "ℹ Using the 'X' assay as the X matrix\n",
    "✔ Selected X matrix [27ms]\n",
    "✔ assays$X converted to X matrix [38ms]\n",
    "✔ additional assays converted to layers [31ms]\n",
    "✔ rowData$varm converted to varm [15ms]\n",
    "✔ reducedDims converted to obsm [63ms]\n",
    "✔ metadata converted to uns [23ms]\n",
    "ℹ rowPairs is empty and was skipped\n",
    "✔ Converting AnnData to SingleCellExperiment ... done\n",
    "AnnData object with n_obs × n_vars = 100 × 2000\n",
    "    obs: 'n_genes_by_counts', 'log1p_n_genes_by_counts', 'total_counts', 'log1p_total_counts', 'pct_counts_in_top_50_genes', 'pct_counts_in_top_100_genes', 'pct_counts_in_top_200_genes', 'pct_counts_in_top_500_genes'\n",
    "    var: 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts', 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
    "    uns: 'X_name', 'hvg', 'log1p', 'neighbors', 'pca', 'umap'\n",
    "    obsm: 'X_pca', 'X_umap'\n",
    "    varm: 'PCs'\n",
    "    layers: 'counts'\n",
    "    obsp: 'connectivities', 'distances'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperability for multimodal data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The developers of the `MuData` object, which we introduced in the [analysis frameworks and tools chapter]({ref}`analysis frameworks and tools chapter <introduction:analysis-frameworks>`) as an extension of `AnnData` for multimodal datasets, have considered interoperability in their design. While the main platform for MuData is Python, the authors have provided the [MuDataSeurat R package](https://pmbio.github.io/MuDataSeurat/) for reading the on-disk H5MU format as `Seurat` objects and the [MuData R package](https://bioconductor.org/packages/MuData/) for doing the same with Bioconductor `MultiAssayExperiment` objects. This official support is very useful but there are still some inconsistencies due to differences between the objects. The MuData authors also provide a [Julia implementation](https://docs.juliahub.com/Muon/QfqCh/0.1.1/objects/) of `AnnData` and `MuData`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interoperability with other languages"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we briefly list some resources and tools for the interoperability of single-cell data with languages other than R and Python.\n",
    "\n",
    "### Julia\n",
    "\n",
    "- [Muon.jl](https://docs.juliahub.com/Muon/QfqCh/0.1.1/objects/) provides Julia implementations of `AnnData` and `MuData` objects, as well as IO for the H5AD and H5MU formats\n",
    "- [scVI.jl](https://github.com/maren-ha/scVI.jl) provides a Julia implementation of `AnnData` as well as IO for the H5AD format\n",
    "\n",
    "### JavaScript\n",
    "\n",
    "- [Vitessce](http://vitessce.io/) contains loaders from `AnnData` objects stored using the Zarr format\n",
    "- The [kana family](https://github.com/jkanche/kana) supports reading H5AD files and `SingleCellExperiment` objects saved as RDS files\n",
    "\n",
    "### Rust\n",
    "\n",
    "- [anndata-rs](https://github.com/kaizhang/anndata-rs) provides a Rust implementation of AnnData as well as advanced IO support for the H5AD format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "anndata             0.9.2\n",
       "anndata2ri          1.2\n",
       "numpy               1.24.4\n",
       "rpy2                3.5.11\n",
       "scanpy              1.9.3\n",
       "scipy               1.9.3\n",
       "session_info        1.0.0\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "CoreFoundation              NA\n",
       "Foundation                  NA\n",
       "PIL                         10.0.0\n",
       "PyObjCTools                 NA\n",
       "anyio                       NA\n",
       "appnope                     0.1.3\n",
       "argcomplete                 NA\n",
       "arrow                       1.2.3\n",
       "asttokens                   NA\n",
       "attr                        23.1.0\n",
       "attrs                       23.1.0\n",
       "babel                       2.12.1\n",
       "backcall                    0.2.0\n",
       "beta_ufunc                  NA\n",
       "binom_ufunc                 NA\n",
       "brotli                      1.0.9\n",
       "certifi                     2023.07.22\n",
       "cffi                        1.15.1\n",
       "charset_normalizer          3.2.0\n",
       "colorama                    0.4.6\n",
       "comm                        0.1.4\n",
       "cycler                      0.10.0\n",
       "cython_runtime              NA\n",
       "dateutil                    2.8.2\n",
       "debugpy                     1.6.8\n",
       "decorator                   5.1.1\n",
       "defusedxml                  0.7.1\n",
       "executing                   1.2.0\n",
       "fastjsonschema              NA\n",
       "fqdn                        NA\n",
       "h5py                        3.9.0\n",
       "hypergeom_ufunc             NA\n",
       "idna                        3.4\n",
       "importlib_metadata          NA\n",
       "importlib_resources         NA\n",
       "ipykernel                   6.25.0\n",
       "ipython_genutils            0.2.0\n",
       "ipywidgets                  8.1.0\n",
       "isoduration                 NA\n",
       "jedi                        0.19.0\n",
       "jinja2                      3.1.2\n",
       "joblib                      1.3.0\n",
       "json5                       NA\n",
       "jsonpointer                 2.0\n",
       "jsonschema                  4.18.6\n",
       "jsonschema_specifications   NA\n",
       "jupyter_events              0.7.0\n",
       "jupyter_server              2.7.0\n",
       "jupyterlab_server           2.24.0\n",
       "kiwisolver                  1.4.4\n",
       "llvmlite                    0.40.1\n",
       "markupsafe                  2.1.3\n",
       "matplotlib                  3.7.2\n",
       "mpl_toolkits                NA\n",
       "natsort                     8.4.0\n",
       "nbformat                    5.9.2\n",
       "nbinom_ufunc                NA\n",
       "ncf_ufunc                   NA\n",
       "numba                       0.57.1\n",
       "objc                        9.2\n",
       "overrides                   NA\n",
       "packaging                   23.1\n",
       "pandas                      2.0.3\n",
       "parso                       0.8.3\n",
       "pexpect                     4.8.0\n",
       "pickleshare                 0.7.5\n",
       "pkg_resources               NA\n",
       "platformdirs                3.10.0\n",
       "prometheus_client           NA\n",
       "prompt_toolkit              3.0.39\n",
       "psutil                      5.9.5\n",
       "ptyprocess                  0.7.0\n",
       "pure_eval                   0.2.2\n",
       "pycparser                   2.21\n",
       "pydev_ipython               NA\n",
       "pydevconsole                NA\n",
       "pydevd                      2.9.5\n",
       "pydevd_file_utils           NA\n",
       "pydevd_plugins              NA\n",
       "pydevd_tracing              NA\n",
       "pygments                    2.15.1\n",
       "pynndescent                 0.5.10\n",
       "pyparsing                   3.0.9\n",
       "pythonjsonlogger            NA\n",
       "pytz                        2023.3\n",
       "referencing                 NA\n",
       "requests                    2.31.0\n",
       "rfc3339_validator           0.1.4\n",
       "rfc3986_validator           0.1.1\n",
       "rpds                        NA\n",
       "rpycall                     NA\n",
       "rpytools                    NA\n",
       "send2trash                  NA\n",
       "six                         1.16.0\n",
       "sklearn                     1.3.0\n",
       "sniffio                     1.3.0\n",
       "socks                       1.7.1\n",
       "stack_data                  0.6.2\n",
       "threadpoolctl               3.2.0\n",
       "tornado                     6.3.2\n",
       "tqdm                        4.65.0\n",
       "traitlets                   5.9.0\n",
       "typing_extensions           NA\n",
       "tzlocal                     NA\n",
       "umap                        0.5.3\n",
       "uri_template                NA\n",
       "urllib3                     2.0.4\n",
       "wcwidth                     0.2.6\n",
       "webcolors                   1.13\n",
       "websocket                   1.6.1\n",
       "yaml                        6.0\n",
       "zipp                        NA\n",
       "zmq                         25.1.0\n",
       "zoneinfo                    NA\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.14.0\n",
       "jupyter_client      8.3.0\n",
       "jupyter_core        5.3.1\n",
       "jupyterlab          3.6.3\n",
       "notebook            6.5.4\n",
       "-----\n",
       "Python 3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:42:20) [Clang 14.0.6 ]\n",
       "macOS-13.4.1-x86_64-i386-64bit\n",
       "-----\n",
       "Session information updated at 2023-08-08 12:03\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "\n",
    "session_info.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# sessioninfo::session_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{bibliography}\n",
    ":filter: docname in docnames\n",
    ":labelprefix: int\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributors\n",
    "\n",
    "We gratefully acknowledge the contributions of:\n",
    "\n",
    "### Authors\n",
    "\n",
    "* Luke Zappia\n",
    "\n",
    "### Reviewers\n",
    "\n",
    "* Lukas Heumos\n",
    "* Isaac Virshup"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "8d105ab5f2493203880d03226e61049059fafcfb5de79a5a432ed345ee74ab31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
